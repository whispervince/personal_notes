### Introduction

##### Offline planning

Agents have full knowledge of both the transition function and the reward function.

For example, in MDP, all the information needed to precompute the optimal actions are encoded in the model.

##### Online planning

Agents have no prior knowledge of the rewards and transitions. An agent must try exploration and receive feedback. The agent uses the feedback to estimate an optimal policy through reinforcement learning before using the policy for exploitation, or reward maximization.











